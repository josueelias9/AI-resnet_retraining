{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 160, 160, 3)]     0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 160, 160, 3)       0         \n",
      "                                                                 \n",
      " tf.math.truediv (TFOpLambda  (None, 160, 160, 3)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " tf.math.subtract (TFOpLambd  (None, 160, 160, 3)      0         \n",
      " a)                                                              \n",
      "                                                                 \n",
      " mobilenetv2_1.00_160 (Funct  (None, 5, 5, 1280)       2257984   \n",
      " ional)                                                          \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 1280)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1280)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 3843      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,261,827\n",
      "Trainable params: 1,865,283\n",
      "Non-trainable params: 396,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### AGREGADO\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load#savedmodel_format\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('./best_weights/mymodel_17-0.0759')\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
      "Requirement already satisfied: numpy>=1.14.5; python_version >= \"3.7\" in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.23.2)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal InRelease [265 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]        \n",
      "Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 Packages [177 kB]\n",
      "Get:6 http://archive.ubuntu.com/ubuntu focal/restricted amd64 Packages [33.4 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 Packages [1275 kB]\n",
      "Get:8 http://archive.ubuntu.com/ubuntu focal/universe amd64 Packages [11.3 MB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1772 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1225 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2738 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [37.7 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [27.5 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [55.2 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2268 kB]\n",
      "Get:16 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [27.5 kB]\n",
      "Get:17 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [927 kB]\n",
      "Get:18 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1655 kB]\n",
      "Fetched 24.2 MB in 5s (5358 kB/s)                      \n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "libsm6 is already the newest version (2:1.2.3-1).\n",
      "libxext6 is already the newest version (2:1.3.4-0ubuntu1).\n",
      "libxrender-dev is already the newest version (1:0.9.10-1).\n",
      "ninja-build is already the newest version (1.10.0-1build1).\n",
      "git is already the newest version (1:2.25.1-1ubuntu3.6).\n",
      "libgl1-mesa-glx is already the newest version (21.2.6-0ubuntu0.1~20.04.2).\n",
      "libglib2.0-0 is already the newest version (2.64.6-1~ubuntu20.04.4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 26 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "### AGREGADO\n",
    "\n",
    "# https://pypi.org/project/opencv-python/\n",
    "!pip install opencv-python\n",
    "\n",
    "# https://github.com/open-mmlab/mmsegmentation/pull/1568/commits/3cdac2f1cb274dc9fc8c9530f997c7ece9ffe074\n",
    "!apt-get update && apt-get install -y git ninja-build libglib2.0-0 libsm6 libxrender-dev libxext6 libgl1-mesa-glx \\\n",
    "    && apt-get clean \\\n",
    "    && rm -rf /var/lib/apt/lists/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "This image most likely belongs to llanta with a 99.99 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "### MODIFICADO\n",
    "\n",
    "# https://www.tensorflow.org/tutorials/images/transfer_learning#evaluation_and_prediction\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('llanta.jpg')\n",
    "\n",
    "b = cv2.resize(image,(160,160))\n",
    "img_array = np.expand_dims(b, axis=0)\n",
    "\n",
    "\n",
    "\n",
    "class_names = [\"interior\",\"exterior\",\"llanta\"]\n",
    "\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = tf.nn.softmax(predictions[0])\n",
    "\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([3.68259971e-05, 1.08849395e-04, 9.99854326e-01], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
